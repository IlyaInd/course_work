{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch_geometric import seed_everything\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PlainData(Data):\n",
    "    \"\"\"\n",
    "    Custom Data class for use in PyG. Basically the same as the original Data class from PyG, but\n",
    "    overrides the __inc__ method because otherwise the DataLoader was incrementing indices unnecessarily.\n",
    "    Now it functions more like the original DataLoader from PyTorch itself.\n",
    "    See here for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html\n",
    "    \"\"\"\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        return 0\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset object containing supervision/evaluation edges. This will be used by the DataLoader to load\n",
    "    batches of edges to calculate loss or evaluation metrics on. Here, get(idx) will return ALL outgoing edges of the graph\n",
    "    corresponding to user \"idx\". This is because when calculating metrics such as recall@k, we need all of the\n",
    "    user's positive edges in the same batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, edge_index, transform=None, pre_transform=None):\n",
    "        self.edge_index = edge_index\n",
    "        self.unique_idxs = torch.unique(edge_index[0,:]).tolist()\n",
    "        self.num_nodes = len(self.unique_idxs)\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    def len(self):\n",
    "        return self.num_nodes\n",
    "\n",
    "    def get(self, idx): # returns all outgoing edges associated with playlist idx\n",
    "        edge_index = self.edge_index[:, self.edge_index[0,:] == idx]\n",
    "        return PlainData(edge_index=edge_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class MovieLens:\n",
    "    def __init__(self):\n",
    "        # df = load_pandas_df('100k', ('UserId', 'ItemId', 'Rating'))\n",
    "        df = pd.read_table('ml-100k/u.data', header=None, usecols=[0, 1, 2])\n",
    "        df.columns = ('UserId', 'ItemId', 'Rating')\n",
    "        df = df[df['Rating'] >= 4]\n",
    "        encoder = LabelEncoder()\n",
    "        df['UserId'] = encoder.fit_transform(df['UserId'])\n",
    "        df['ItemId'] = encoder.fit_transform(df['ItemId'])\n",
    "        df['ItemId'] += df['UserId'].max() + 1\n",
    "        self.num_users = df['UserId'].nunique()\n",
    "        self.df = df\n",
    "        self._build_graph()\n",
    "        self._train_test_split()\n",
    "\n",
    "    def _build_edge_index(self):\n",
    "        users = torch.tensor(self.df['UserId'].values, dtype=torch.long)\n",
    "        items = torch.tensor(self.df['ItemId'].values, dtype=torch.long)\n",
    "        source = torch.cat([users, items]).reshape(1, -1)\n",
    "        target = torch.cat([items, users]).reshape(1, -1)\n",
    "        edges = torch.cat([source, target], dim=0)\n",
    "        return edges\n",
    "\n",
    "    def _build_graph(self):\n",
    "        edges = self._build_edge_index()\n",
    "        self.num_nodes = len(edges.unique())\n",
    "        self.edges = edges\n",
    "        graph = Data(edge_index=edges, num_nodes=self.num_nodes)\n",
    "        self.graph = graph\n",
    "\n",
    "    def _train_test_split(self, val_ratio=0.15, test_ratio=0.15):\n",
    "        splitter = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False,\n",
    "                                   neg_sampling_ratio=0, num_val=val_ratio, num_test=test_ratio)\n",
    "        train_split, val_split, test_split = splitter(self.graph)\n",
    "        # Confirm that every node appears in every set above\n",
    "        assert train_split.num_nodes == val_split.num_nodes and train_split.num_nodes == test_split.num_nodes\n",
    "\n",
    "        self.train_split = train_split\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "\n",
    "    def get_train(self):\n",
    "        train_ev = MyDataset('movielens', edge_index=self.train_split.edge_label_index)\n",
    "        train_mp = Data(edge_index=self.train_split.edge_index)\n",
    "        return train_ev, train_mp\n",
    "\n",
    "    def get_val(self):\n",
    "        val_ev = MyDataset('movielens', edge_index=self.val_split.edge_label_index)\n",
    "        val_mp = Data(edge_index=self.val_split.edge_index)\n",
    "        return val_ev, val_mp\n",
    "\n",
    "    def get_test(self):\n",
    "        test_ev = MyDataset('movielens', edge_index=self.test_split.edge_label_index)\n",
    "        test_mp = Data(edge_index=self.test_split.edge_index)\n",
    "        return test_ev, test_mp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mov = MovieLens()\n",
    "\n",
    "train_ev, train_mp = mov.get_train()\n",
    "val_ev, val_mp = mov.get_val()\n",
    "test_ev, test_mp = mov.get_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LightGCN\n",
    "__TODO:__\n",
    "- Переписать метод `recommend`, чтобы была возможность рекомендовать только ранее не виденные айтемы. Оставить и обычное поведение тоже, чтобы была возможность тестировать на трейне.\n",
    "\n",
    "\n",
    "- Добавить в `__init__()` поля с количеством юзеров и пользователей. Подумать, в какой класс это добавить."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "class CustomLightGCN(LightGCN):\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight, gain=1)\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_ev, val_ev, batch_size=256):\n",
    "        self.model = model\n",
    "        self.opt = optimizer\n",
    "        self.train_loader = DataLoader(train_ev, batch_size=batch_size, shuffle=True)\n",
    "        self.val_loader = DataLoader(val_ev, batch_size=batch_size, shuffle=False)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = self.model.to(self.device)\n",
    "\n",
    "        self.global_train_step = 0\n",
    "        self.global_val_step = 0\n",
    "        self.writer = SummaryWriter(\"./logs\")\n",
    "\n",
    "        # сохраняем состояние оптимизатора и модели\n",
    "        # self.cache = self.cache_states()\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_negative_edges(batch, data_mp, num_users, num_nodes):\n",
    "        negs = []\n",
    "        for i in batch.edge_index[0, :]:  # looping over users\n",
    "            assert i < num_users     # just ensuring that i is a user\n",
    "            rand_item = torch.randint(num_users, num_nodes, (1,))  # randomly sample an item\n",
    "            negs.append(rand_item.item())\n",
    "        edge_index_negs = torch.row_stack([batch.edge_index[0, :], torch.LongTensor(negs)])\n",
    "        return Data(edge_index=edge_index_negs, y=torch.LongTensor([0] * len(negs)))\n",
    "\n",
    "\n",
    "    def train(self, data_mp, k, num_users, num_nodes):\n",
    "        model = self.model\n",
    "        opt = self.opt\n",
    "        items = torch.tensor(np.arange(num_users, num_nodes))\n",
    "        recall_all = []\n",
    "\n",
    "        model.train()\n",
    "        for batch in self.train_loader:\n",
    "            del batch.batch; del batch.ptr # delete unwanted attributes\n",
    "\n",
    "            opt.zero_grad()\n",
    "            negs = self.sample_negative_edges(batch, data_mp, num_users, num_nodes)  # sample negative edges\n",
    "            data_mp, batch, negs = data_mp.to(self.device), batch.to(self.device), negs.to(self.device)\n",
    "\n",
    "            pos_scores = model.forward(data_mp['edge_index'], batch['edge_index'])\n",
    "            neg_scores = model.forward(data_mp['edge_index'], negs['edge_index'])\n",
    "\n",
    "            batch_index = batch['edge_index']\n",
    "            users = batch_index[0].unique()\n",
    "            recoms = model.recommend(data_mp['edge_index'], users, items, k=k)\n",
    "\n",
    "            recall_batch = []\n",
    "            for u, rec in zip(users, recoms):\n",
    "                true_items = batch_index[1, batch_index[0] == u].cpu()\n",
    "                hits = len(np.intersect1d(rec.cpu(), true_items))\n",
    "                recall = hits / len(true_items)\n",
    "                recall_batch.append(recall)\n",
    "                recall_all.append(recall)\n",
    "\n",
    "            # loss = pos_scores.shape[0] * model.recommendation_loss(pos_scores, neg_scores)\n",
    "            loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "            loss.backward()\n",
    "            # for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
    "            #     print(f'Gradient norm on this layer = {p.grad.data.norm(2).item()}')  # Посмотрим на норму градиентов\n",
    "            opt.step()\n",
    "\n",
    "            self.writer.add_scalar(\"Recall/train\", np.mean(recall_batch), global_step=self.global_train_step)\n",
    "            self.writer.add_scalar(\"Loss/train\", loss.item(), global_step=self.global_train_step)\n",
    "            self.global_train_step += 1\n",
    "\n",
    "        print(f'Train avg recall = {np.mean(recall_all).round(4)}')\n",
    "        print(f'Current loss = {loss.item()}')\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def test(self, data_mp, k, num_users, num_nodes, train_split=None):\n",
    "        model = self.model\n",
    "        items = torch.LongTensor(np.arange(num_users, num_nodes))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data_mp = data_mp.to(self.device)\n",
    "\n",
    "            recall_all = []\n",
    "            for batch in self.val_loader:\n",
    "                del batch.batch; del batch.ptr # delete unwanted attributes\n",
    "                batch = batch['edge_index']\n",
    "                batch = batch.to(self.device)\n",
    "                users = batch[0].unique_consecutive()\n",
    "                recoms = model.recommend(data_mp['edge_index'], users, items, k=k)\n",
    "\n",
    "                # --- FAIR BUT LONG METHOD ---\n",
    "                # for user in tqdm(users):\n",
    "                    # seen_items = set(train_split[1, train_split[0] == user].tolist())\n",
    "                    # unseen_items = torch.LongTensor(list(items.difference(seen_items)))\n",
    "                    # rec = model.recommend(data_mp['edge_index'], user, torch.tensor(list(items)), k=k)\n",
    "                    # true_items = batch[1, batch[0] == user].cpu()\n",
    "\n",
    "                recall_batch = []\n",
    "                for u, rec in zip(users, recoms):\n",
    "                    true_items = batch[1, batch[0] == u].cpu()\n",
    "                    hits = len(np.intersect1d(rec.cpu(), true_items))\n",
    "                    recall = hits / len(true_items)\n",
    "                    recall_batch.append(recall)\n",
    "                    recall_all.append(recall)\n",
    "\n",
    "                self.writer.add_scalar(\"Recall/valid\", np.mean(recall_batch), global_step=self.global_val_step)\n",
    "                self.global_val_step += 1\n",
    "\n",
    "        print(f'Valid avg recall = {np.mean(recall_all).round(4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}